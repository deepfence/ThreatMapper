from flask import Blueprint, request
from sqlalchemy.exc import IntegrityError
import logging
import io
import csv
from flask_jwt_extended import jwt_required, get_jwt_identity
from flask_restful import Resource, Api
from datetime import datetime
import urllib.parse
import magic
from utils.helper import websocketio_channel_name_format, split_list_into_chunks, get_recent_scan_ids, \
    is_network_attack_vector, get_topology_network_graph, get_image_cve_status
from utils.response import set_response, format_response
from utils.common import calculate_interval, format_es_resp_for_api
from utils.custom_exception import InvalidUsage, InternalError, DFError
from utils.esconn import ESConn, GroupByParams
from utils.es_query_utils import get_latest_cve_scan_id
from utils.constants import CVE_INDEX, TIME_UNIT_MAPPING, USER_ROLES, ES_TERMS_AGGR_SIZE, NODE_TYPE_CONTAINER, \
    NODE_TYPE_HOST, CVE_SCAN_TYPES, NODE_TYPE_CONTAINER_IMAGE, REGISTRY_IMAGES_CACHE_KEY_PREFIX, \
    MAX_TOTAL_SEVERITY_SCORE, MAX_TOP_EXPLOITABLE_VULNERABILITIES, REGISTRY_TYPE_GCLOUD, TOPOLOGY_FILTERS_PREFIX, \
    NODE_TYPE_REGISTRY_IMAGE, DF_ID_TO_SCOPE_ID_REDIS_KEY_PREFIX, NODE_ACTION_CVE_SCAN_START, ES_MAX_CLAUSE, \
    CVE_SCAN_LOGS_INDEX
from utils.decorators import user_permission, non_read_only_user
from models.node_tags import NodeTags
from models.container_image_registry import RegistryCredential
from models.user import User
from collections import defaultdict
from resource_models.node import Node
import pandas as pd
import json
import time
from config.redisconfig import redis
from cve_scan_registry.scan_registry.cve_scan_registry import DFError as DFErrorFromThreatMapper
from utils.resource import filter_node_for_vulnerabilities, get_scan_status_for_registry_images
import networkx as nx
from utils.node_utils import NodeUtils

vulnerability_api = Blueprint("vulnerability_api", __name__)
vulnerability_api_restful = Api(vulnerability_api)


@vulnerability_api.route("/vulnerabilities/cve_severity_chart", methods=["GET", "POST"])
@jwt_required
def vulnerability_severity_chart():
    """
    Vulnerability severity chart.
    ---
    tags:
      - Vulnerabilities API
    security:
      - Bearer: []
    parameters:
      - name: number
        in: query
        type: string
        required: true
        description: Number of (months, days, hours, minutes).
      - name: time_unit
        in: query
        type: string
        required: true
        description: Time unit (month/day/hour/minute).
      - name: lucene_query
        in: query
        type: string
        required: false
        description: Lucene query.
    responses:
      200:
        description: with a valid request and response ... uses standard response codes
      400:
        description: bad request (like missing text data)
    """
    number = request.args.get("number")
    time_unit = request.args.get("time_unit")
    lucene_query_string = request.args.get("lucene_query")
    if lucene_query_string:
        lucene_query_string = urllib.parse.unquote(lucene_query_string)

    if number is None:
        raise InvalidUsage("Number parameter is required.")

    try:
        number = int(number)
    except ValueError:
        raise InvalidUsage("Number should be an integer value.")

    try:
        number = int(number)
    except ValueError:
        raise InvalidUsage("Number should be an integer value.")

    if bool(number is not None) ^ bool(time_unit):
        raise InvalidUsage("Require both number and time_unit or ignore both of them.")

    interval = calculate_interval(number, time_unit)
    if not interval:
        raise InvalidUsage("Unsupported number and time_unit combination")

    filters = {}
    if request.is_json:
        if type(request.json) != dict:
            raise InvalidUsage("Request data invalid")
        filters = request.json.get("filters", {})

    params = GroupByParams(CVE_INDEX)
    params.addrelativetimerange(number, time_unit)
    params.addlucenequery(lucene_query_string)
    params.add_agg_field('cve_severity.keyword', 'terms', order={"_count": "desc"})
    params.add_sub_agg_field('cve_type.keyword', 'terms', order={"_count": "desc"})
    aggs_name = 'by_severity'
    sub_aggs_name = 'by_type'

    for key, value in filters.items():
        params.add_filter('term', "{0}.keyword".format(key), value)

    cve_aggs = ESConn.group_by(params, aggs_name, sub_aggs_name=sub_aggs_name)
    # print(cve_aggs)

    data = {"name": "Alerts", "children": []}
    inner_children = []
    cve_by_severity = cve_aggs.get(aggs_name, {}).get('buckets', [])
    for bucket in cve_by_severity:
        by_severity = {}
        by_severity["name"] = bucket.get('key')
        by_severity["children"] = []
        total_count = 0
        for inner_bucket in bucket.get(sub_aggs_name, {}).get('buckets', []):
            total_count += inner_bucket.get("doc_count")
            child = {"name": inner_bucket.get("key"), "value": inner_bucket.get("doc_count")}
            by_severity["children"].append(child)
        by_severity["value"] = total_count
        inner_children.append(by_severity)
    data["children"] = inner_children

    return set_response(data=data)


@vulnerability_api.route("/vulnerabilities/report/<aggregation_type>", methods=["GET", "POST"])
@jwt_required
def cve_aggregation(aggregation_type):
    """
    :param aggregation_type: severity | cve_type
    :return
    For aggregation_type=severity
    {
      "critical": 34,
      "high": 10,
      "low": 30,
      "medium": 30
    }
    """
    aggregation_types = {"severity": "cve_severity", "cve_type": "cve_type"}
    if not aggregation_type or aggregation_type not in aggregation_types:
        raise InvalidUsage("Invalid aggregation_type: {0}".format(aggregation_type))
    aggs_type = aggregation_types[aggregation_type]

    number = request.args.get("number")
    time_unit = request.args.get("time_unit")

    if number:
        try:
            number = int(number)
        except ValueError:
            raise InvalidUsage("Number should be an integer value.")

    if bool(number is not None) ^ bool(time_unit):
        raise InvalidUsage("Require both number and time_unit or ignore both of them.")

    if time_unit and time_unit not in TIME_UNIT_MAPPING.keys():
        raise InvalidUsage("time_unit should be one of these, month/day/hour/minute")

    lucene_query_string = request.args.get("lucene_query")
    if lucene_query_string:
        lucene_query_string = urllib.parse.unquote(lucene_query_string)

    scan_ids = get_latest_cve_scan_id()

    filters = {}
    if request.is_json:
        if type(request.json) != dict:
            raise InvalidUsage("Request data invalid")
        filters = request.json.get("filters", {})
    filters["type"] = CVE_INDEX
    # TODO: maxClause issue
    filters["scan_id"] = scan_ids[:ES_MAX_CLAUSE]
    aggs = {
        aggs_type: {
            "terms": {
                "field": "{0}.keyword".format(aggs_type),
                "size": ES_TERMS_AGGR_SIZE
            },
            "aggs": {
                "severity": {
                    "terms": {
                        "field": "cve_severity.keyword",
                    },  # TODO: sub aggregation should be configurable from request
                    "aggs": {
                        "cveid_count": {
                            "cardinality": {
                                "field": "cve_id.keyword",
                            }
                        }
                    }
                }
            }
        }
    }
    aggs_response = ESConn.aggregation_helper(
        CVE_INDEX,
        filters,
        aggs,
        number,
        TIME_UNIT_MAPPING.get(time_unit),
        lucene_query_string
    )

    response = []

    # if "aggregations" in aggs_response:
    #     for bucket in aggs_response["aggregations"][aggs_type]["buckets"]:
    #         sub_buckets = bucket.get("severity", []).get("buckets", [])
    #         severity_values = {}
    #         for sub_bucket in sub_buckets:
    #             cveid_unique_count = sub_bucket.get('cveid_count', {}).get('value', 0)
    #             severity_values[sub_bucket.get("key")] = cveid_unique_count
    #             # severity_values[sub_bucket.get("key")] = sub_bucket.get("doc_count")
    #         response[bucket["key"]] = {
    #             "value": sum(severity_values.values()),
    #             "severity": severity_values,
    #         }

    if "aggregations" in aggs_response:
        for bucket in aggs_response["aggregations"][aggs_type]["buckets"]:
            sub_buckets = bucket.get("severity", []).get("buckets", [])
            for sub_bucket in sub_buckets:
                info = {}
                info['cve_type'] = bucket.get("key")
                info['value'] = sub_bucket.get('cveid_count', {}).get('value', 0)
                info['type'] = sub_bucket.get("key")
                response.append(info)

    return set_response(data=response)


@vulnerability_api.route("/vulnerabilities/image_report", methods=["GET", "POST"])
@jwt_required
def cve_image_report():
    """
    :return:
    {
      "wordpress:3.4.2": {
        "severity": {
            "critical": 30,
            "high": 10,
            "medium": 30,
            "low": 34
        },
        "active_containers": 2,
        "total": 104,
        "time_stamp": "2018-10-06T09:02:47.266Z",
        "scan_id": "wordpress:3.4.2_2019-08-20T05:56:18.967",
        "node_type": "container_image"
      }
    }
    """
    number = request.args.get("number")
    time_unit = request.args.get("time_unit")

    if number:
        try:
            number = int(number)
        except ValueError:
            raise InvalidUsage("Number should be an integer value.")

    if bool(number is not None) ^ bool(time_unit):
        raise InvalidUsage("Require both number and time_unit or ignore both of them.")

    if time_unit and time_unit not in TIME_UNIT_MAPPING.keys():
        raise InvalidUsage("time_unit should be one of these, month/day/hour/minute")

    lucene_query_string = request.args.get("lucene_query")
    if lucene_query_string:
        lucene_query_string = urllib.parse.unquote(lucene_query_string)
    filters = {}
    node_filters = {}
    page_size = 10
    start_index = 0
    if request.is_json:
        if type(request.json) != dict:
            raise InvalidUsage("Request data invalid")
        filters = request.json.get("filters", {})
        node_filters = request.json.get("node_filters", {})
        page_size = request.json.get("size", page_size)
        start_index = request.json.get("start_index", start_index)
    filters["type"] = CVE_INDEX
    node_filters_for_cve_scan_index = {}
    if node_filters:
        node_filters_for_cve_index, node_filters_for_cve_scan_index = filter_node_for_vulnerabilities(node_filters)
        if node_filters_for_cve_index:
            filters = {**filters, **node_filters_for_cve_index}
    # To include nodes which have been scanned but resulted in zero vulnerabilities,
    # we loop through the CVE_SCAN_LOG and attach the default values
    filters_cve_scan = {"action": ["COMPLETED", "ERROR"]}
    filters_cve_scan.update({**request.json.get("filters", {})})
    if node_filters_for_cve_scan_index:
        filters_cve_scan = {**filters_cve_scan, **node_filters_for_cve_scan_index}
    aggs_cve_scan = {
        "node_id": {
            "terms": {
                "field": "node_id.keyword",
                "size": ES_TERMS_AGGR_SIZE
            },
            "aggs": {
                "scan_id": {
                    "terms": {
                        "field": "scan_id.keyword",
                        "size": ES_TERMS_AGGR_SIZE
                    },
                    "aggs": {
                        "scan_recent_timestamp": {
                            "max": {
                                "field": "@timestamp"
                            }
                        },
                        "cve_scan_errors": {
                            "filter": {"term": {"action.keyword": "ERROR"}},
                            "aggs": {
                                "cve_scan_message": {
                                    "terms": {
                                        "field": "cve_scan_message.keyword",
                                        "size": ES_TERMS_AGGR_SIZE
                                    }
                                }
                            }
                        }
                    }
                },
                "node_type": {
                    "terms": {
                        "field": "node_type.keyword",
                        "size": 1
                    },
                }
            }
        }
    }
    aggs_query_cve_scan = ESConn.aggregation_helper(
        CVE_SCAN_LOGS_INDEX, filters_cve_scan, aggs_cve_scan, number, TIME_UNIT_MAPPING.get(time_unit),
        lucene_query_string, add_masked_filter=False, get_only_query=True)
    cve_scan_resp = ESConn.search(CVE_SCAN_LOGS_INDEX, aggs_query_cve_scan, start_index, page_size)
    filters["scan_id"] = []
    cve_scan_messages = {}
    cve_scan_actions = {}
    if "aggregations" in cve_scan_resp:
        for image_aggr in cve_scan_resp["aggregations"]["node_id"]["buckets"]:
            for scan_id_aggr in image_aggr["scan_id"]["buckets"]:
                filters["scan_id"].append(scan_id_aggr["key"])
                cve_scan_actions[scan_id_aggr["key"]] = "ERROR" if scan_id_aggr["cve_scan_errors"][
                                                                       "doc_count"] > 0 else "COMPLETED"
                if scan_id_aggr["cve_scan_errors"]["doc_count"] > 0:
                    cve_scan_messages[scan_id_aggr["key"]] = ", ".join(
                        bucket["key"] for bucket in scan_id_aggr["cve_scan_errors"]["cve_scan_message"]["buckets"])
    aggs = {
        "cve_container_image": {
            "terms": {
                "field": "cve_container_image.keyword",
                "size": ES_TERMS_AGGR_SIZE
            },
            "aggs": {
                "scan_id": {
                    "terms": {
                        "field": "scan_id.keyword",
                        "size": ES_TERMS_AGGR_SIZE
                    },
                    "aggs": {
                        "cve_severity": {
                            "terms": {
                                "field": "cve_severity.keyword",
                                "size": ES_TERMS_AGGR_SIZE
                            }
                        },
                        "scan_recent_timestamp": {
                            "max": {
                                "field": "@timestamp"
                            }
                        },
                        "cve_score": {
                            "sum": {
                                "field": "cve_overall_score"
                            }
                        }
                    }
                },
                "host_name": {
                    "terms": {
                        "field": "host_name.keyword",
                        "size": 1
                    },
                }
            }
        }
    }
    aggs_query = ESConn.aggregation_helper(
        CVE_INDEX, filters, aggs, number, TIME_UNIT_MAPPING.get(time_unit), lucene_query_string,
        get_only_query=True)
    cve_resp = ESConn.search(CVE_INDEX, aggs_query, start_index, page_size)
    active_containers = defaultdict(int)
    containers_topology_data = redis.get(
        websocketio_channel_name_format("{0}?format=deepfence".format(NODE_TYPE_CONTAINER))[1])
    if containers_topology_data:
        containers_topology_data = json.loads(containers_topology_data)
        for df_id, container in containers_topology_data.items():
            if container.get("image_name"):
                if container.get("docker_container_state") != "running":
                    continue
                active_containers[
                    "{0}:{1}".format(container.get("image_name", ""), container.get("image_tag", ""))] += 1
    scanned_node_response = defaultdict(list)
    image_scan_id_map = defaultdict(set)
    if "aggregations" in cve_resp:
        for image_aggr in cve_resp["aggregations"]["cve_container_image"]["buckets"]:
            node_type = NODE_TYPE_CONTAINER_IMAGE
            if image_aggr["host_name"]["buckets"]:
                host_name = image_aggr["host_name"]["buckets"][0]["key"]
                if host_name == image_aggr["key"]:
                    node_type = NODE_TYPE_HOST
            for scan_id_aggr in image_aggr["scan_id"]["buckets"]:
                scan_details = {
                    "active_containers": active_containers.get(image_aggr["key"], 0),
                    "total": scan_id_aggr["doc_count"],
                    "cve_score": min(scan_id_aggr["cve_score"]["value"] * 10.0 / MAX_TOTAL_SEVERITY_SCORE, 10.0),
                    "time_stamp": scan_id_aggr["scan_recent_timestamp"]["value_as_string"], "severity": {},
                    "cve_scan_message": cve_scan_messages.get(scan_id_aggr["key"], ""),
                    "action": cve_scan_actions.get(scan_id_aggr["key"], "COMPLETED"),
                    "scan_id": scan_id_aggr["key"], "node_name": image_aggr["key"], "node_type": node_type}
                for severity_aggr in scan_id_aggr["cve_severity"]["buckets"]:
                    scan_details["severity"][severity_aggr["key"]] = severity_aggr["doc_count"]
                scanned_node_response[image_aggr["key"]].append(scan_details)
                image_scan_id_map[image_aggr["key"]].add(scan_id_aggr["key"])
    if "aggregations" in cve_scan_resp:
        for image_aggr in cve_scan_resp["aggregations"]["node_id"]["buckets"]:
            node_type = NODE_TYPE_CONTAINER_IMAGE
            if image_aggr["node_type"]["buckets"]:
                node_type = image_aggr["node_type"]["buckets"][0]["key"]
            for scan_id_aggr in image_aggr["scan_id"]["buckets"]:
                if scan_id_aggr["key"] not in image_scan_id_map[image_aggr["key"]]:
                    scanned_node_response[image_aggr["key"]].append({
                        "active_containers": active_containers.get(image_aggr["key"], 0),
                        "cve_score": 0, "total": 0, "severity": {"low": 0, "medium": 0, "high": 0, "critical": 0},
                        "time_stamp": scan_id_aggr["scan_recent_timestamp"]["value_as_string"],
                        "cve_scan_message": cve_scan_messages.get(scan_id_aggr["key"], ""),
                        "action": cve_scan_actions.get(scan_id_aggr["key"], "COMPLETED"),
                        "scan_id": scan_id_aggr["key"], "node_name": image_aggr["key"], "node_type": node_type})
    response = []
    for node_name, scan_list in scanned_node_response.items():
        tmp_list = sorted(scan_list, key=lambda k: k["time_stamp"], reverse=True)
        error_scan_count = sum(scan["action"] == "ERROR" for scan in scan_list)
        if not tmp_list:
            continue
        response.append({
            "node_name": tmp_list[0]["node_name"],
            "node_type": tmp_list[0]["node_type"],
            "scans": tmp_list,
            "time_stamp": tmp_list[0]["time_stamp"],
            "error_count": error_scan_count,
            "total_count": len(scan_list),
        })
    response = sorted(response, key=lambda k: k["time_stamp"], reverse=True)
    return set_response(data={"data": response[start_index:(start_index + page_size)], "total": len(response)})


def mask_vulnerabilities(es_resp):
    docs_to_be_masked = [{"_index": doc["_index"], "_id": doc["_id"]} for doc in es_resp]
    ESConn.bulk_mask_docs(docs_to_be_masked)
    return len(docs_to_be_masked)


source_detailed = [
    "@timestamp", "container_name", "cve_attack_vector", "cve_caused_by_package", "cve_container_image",
    "cve_container_image_id", "cve_container_layer", "cve_cvss_score", "cve_description", "cve_fixed_in", "cve_id",
    "cve_link", "cve_overall_score", "cve_severity", "cve_type", "doc_id", "geoip", "host", "host_name",
    "input_type", "type", "scan_id"]


@vulnerability_api.route("/vulnerability_scan_diff", methods=["GET"], endpoint="api_v1_5_vulnerability_scan_diff")
@jwt_required
def vulnerability_scan_diff():
    """
    Get vulnerability scan diff between two scan ids for scans of same image or host
    ---
    tags:
      - Vulnerability Management
    operationId: getVulnerabilityScanDiff
    security:
      - Bearer: []
    description: Get vulnerability scan diff between two scan ids for scans of same image or host
    parameters:
    - name: scan_id
      in: query
      description: scan_id of the vulnerability scan
      type: string
      required: true
    - name: compare_with_scan_id
      in: query
      description: scan_id of the vulnerability scan to be compared with
      type: string
      required: true
    responses:
      200:
        description: Request success
        properties:
          data:
            type: object
            description: Response message
            properties:
              message:
                type: string
          error:
            type: string
            description: Error message, if any. Otherwise `null`
          success:
            type: boolean
            description: Success status
            enum: [true, false]
      400:
        description: Bad request
      401:
        description: Unauthorized
    """
    scan_id_1 = request.args.get("scan_id", None)
    if not scan_id_1:
        raise InvalidUsage("scan_id is required.")
    scan_id_2 = request.args.get("compare_with_scan_id", None)
    if not scan_id_2:
        raise InvalidUsage("compare_with_scan_id is required.")
    filters = {"type": "cve", "masked": "false", "scan_id": [scan_id_1, scan_id_2]}
    es_resp = ESConn.search_by_and_clause(CVE_INDEX, filters, 0, "desc", size=20000, _source=source_detailed)
    cve_results = []
    diff_cves = []
    for es_doc in es_resp.get("hits", []):
        cve_results.append({**es_doc["_source"], **{"_id": es_doc["_id"]}})
    if cve_results:
        def diff_dfs(df1, df2, how="left"):
            """
              Find Difference of rows for given two dataframes
              this function is not symmetric, means
                    diff(x, y) != diff(y, x)
              however
                    diff(x, y, how='left') == diff(y, x, how='right')
              Ref: https://stackoverflow.com/questions/18180763/set-difference-for-pandas/40209800#40209800
            """
            if (df1.columns != df2.columns).any():
                raise ValueError("Two dataframe columns must match")

            if df1.equals(df2):
                return None
            elif how == 'right':
                return pd.concat([df2, df1, df1]).drop_duplicates(keep=False)
            elif how == 'left':
                return pd.concat([df1, df2, df2]).drop_duplicates(keep=False)
            else:
                raise ValueError('how parameter supports only "left" or "right keywords"')

        cve_results_df = pd.DataFrame(cve_results)
        cve_results_df_1 = cve_results_df.loc[(cve_results_df.scan_id == scan_id_1)]
        cve_results_df_2 = cve_results_df.loc[(cve_results_df.scan_id == scan_id_2)]
        added_cves = diff_dfs(cve_results_df_1[["cve_caused_by_package", "cve_container_image", "cve_id"]],
                              cve_results_df_2[["cve_caused_by_package", "cve_container_image", "cve_id"]], how="right")
        del_cves = diff_dfs(cve_results_df_1[["cve_caused_by_package", "cve_container_image", "cve_id"]],
                            cve_results_df_2[["cve_caused_by_package", "cve_container_image", "cve_id"]], how="left")
        common_cves = pd.merge(cve_results_df_1[["cve_caused_by_package", "cve_container_image", "cve_id"]],
                               cve_results_df_2[["cve_caused_by_package", "cve_container_image", "cve_id"]],
                               how="inner")
        added_cves_index = list(added_cves.index)
        added_cves_full = cve_results_df_2[cve_results_df_2.index.isin(added_cves_index)]
        del_cves_index = list(del_cves.index)
        del_cves_full = cve_results_df_1[cve_results_df_1.index.isin(del_cves_index)]
        common_cves_index = list(common_cves.index)
        common_cves_full = cve_results_df_1[cve_results_df_1.index.isin(common_cves_index)]
        added_cves_json = added_cves_full.to_dict('records')
        del_cves_json = del_cves_full.to_dict('records')
        common_cves_json = common_cves_full.to_dict('records')
        for cve in added_cves_json:
            tmp_json = {"_id": cve["_id"], "_source": {**cve, **{"diff": "new"}}}
            del tmp_json["_source"]["_id"]
            diff_cves.append(tmp_json)
        for cve in del_cves_json:
            tmp_json = {"_id": cve["_id"], "_source": {**cve, **{"diff": "fixed"}}}
            del tmp_json["_source"]["_id"]
            diff_cves.append(tmp_json)
        for cve in common_cves_json:
            tmp_json = {"_id": cve["_id"], "_source": {**cve, **{"diff": "not_fixed"}}}
            del tmp_json["_source"]["_id"]
            diff_cves.append(tmp_json)
    return set_response(data=format_es_resp_for_api(diff_cves, "vulnerability_id"))


@vulnerability_api.route("/vulnerability_scan_history", methods=["GET"], endpoint="api_v1_5_vulnerability_scan_history")
@jwt_required
def vulnerability_scan_history():
    """
    Get vulnerability scan history
    ---
    tags:
      - Vulnerability Management
    operationId: getVulnerabilityScanHistory
    security:
      - Bearer: []
    description: Get vulnerability scan history
    responses:
      200:
        description: Request success
        properties:
          data:
            type: object
            description: Response message
            properties:
              message:
                type: string
          error:
            type: string
            description: Error message, if any. Otherwise `null`
          success:
            type: boolean
            description: Success status
            enum: [true, false]
      400:
        description: Bad request
      401:
        description: Unauthorized
    """
    number = request.args.get("number")
    time_unit = request.args.get("time_unit")

    if number:
        try:
            number = int(number)
        except ValueError:
            raise InvalidUsage("Number should be an integer value.")

    if bool(number is not None) ^ bool(time_unit):
        raise InvalidUsage("Require both number and time_unit or ignore both of them.")

    if time_unit and time_unit not in TIME_UNIT_MAPPING.keys():
        raise InvalidUsage("time_unit should be one of these, month/day/hour/minute")

    lucene_query_string = request.args.get("lucene_query")
    if lucene_query_string:
        lucene_query_string = urllib.parse.unquote(lucene_query_string)
    aggs = {
        "node_id": {
            "terms": {
                "field": "node_id.keyword",
                "size": ES_TERMS_AGGR_SIZE
            },
            "aggs": {
                "scan_id": {
                    "terms": {
                        "field": "scan_id.keyword",
                        "size": ES_TERMS_AGGR_SIZE
                    },
                },
                "node_type": {
                    "terms": {
                        "field": "node_type.keyword",
                        "size": ES_TERMS_AGGR_SIZE
                    },
                }
            }
        }
    }
    aggs_response = ESConn.aggregation_helper(
        CVE_SCAN_LOGS_INDEX, {"action": "COMPLETED"}, aggs, number, TIME_UNIT_MAPPING.get(time_unit),
        lucene_query_string, add_masked_filter=False)
    response = defaultdict(list)
    if "aggregations" in aggs_response:
        for node_id_bkt in aggs_response["aggregations"]["node_id"]["buckets"]:
            node_type = ""
            for node_type_bkt in node_id_bkt["node_type"]["buckets"]:
                node_type = node_type_bkt["key"]
            for scan_id_bkt in node_id_bkt["scan_id"]["buckets"]:
                response[node_id_bkt["key"]].append(
                    {"scan_id": scan_id_bkt["key"], "node_type": node_type, "@timestamp": scan_id_bkt["key"][-23:]})
    return set_response(data=dict(response))


@vulnerability_api.route("/vulnerability", methods=["POST"], endpoint="api_v1_5_vulnerability_mgmt_post")
@jwt_required
def vulnerability_management_post():
    """
    Get/Delete vulnerabilities by filter
    ---
    tags:
      - Vulnerability Management
    operationId: findVulnerability
    security:
      - Bearer: []
    description: Get/Delete vulnerabilities by filter
    parameters:
    - in: body
      name: Options
      description: Options to get or delete vulnerabilities
      schema:
        type: object
        properties:
          action:
            type: string
            enum: [get, delete]
            default: get
            description: Action to perform - `get` or `delete`
          group_by:
            type: string
            description: Optionally group by cve_caused_by_package | cve_id
            example: cve_caused_by_package
          size:
            type: integer
            example: 10
            default: 10
            minimum: 1
            maximum: 10000
            description: The numbers of vulnerabilities to return
          start_index:
            type: integer
            example: 0
            minimum: 0
            maximum: 9999
            default: 0
            description: The number of items to skip before starting to collect the result set
          filters:
            description: Filter vulnerabilities by various fields (key value pairs)
            type: object
            properties:
              cve_severity:
                type: array
                uniqueItems: true
                description: CVE severity
                example: ["critical"]
                items:
                  type: string
                  enum: [critical, high, medium, low]
              host_name:
                type: array
                uniqueItems: true
                description: Host names
                example: ["dev-1", "dev-2"]
                items:
                  type: string
              scan_id:
                type: array
                uniqueItems: true
                description: scan ids
                example: ["scan1", "scan2"]
                items:
                  type: string
              container_name:
                type: array
                uniqueItems: true
                description: Container names
                example: ["container-1", "container-2"]
                items:
                  type: string
              vulnerability_id:
                type: array
                uniqueItems: true
                description: Vulnerability ids
                example: ["ewqvfewqk", "ewokwlkevf"]
                items:
                  type: string
              cve_container_image:
                type: array
                uniqueItems: true
                description: Container image names
                example: ["dev-1", "dev-2"]
                items:
                  type: string
              cve_container_image_id:
                type: array
                uniqueItems: true
                description: Container image ids
                example: ["ewqlkfn"]
                items:
                  type: string
              cve_id:
                type: array
                uniqueItems: true
                description: CVE Id
                example: ["CVE-2018-9234"]
                items:
                  type: string
    responses:
      200:
        description: Request success
        properties:
          data:
            type: object
            description: Response message
            properties:
              message:
                type: string
          error:
            type: string
            description: Error message, if any. Otherwise `null`
          success:
            type: boolean
            description: Success status
            enum: [true, false]
      400:
        description: Bad request
      401:
        description: Unauthorized
    """
    if not request.is_json:
        raise InvalidUsage("Missing JSON in request")
    req_json = request.json
    action = req_json.get("action", "get")
    filters = req_json.get("filters", {})
    if not filters:
        filters = {"type": "cve"}

    # if "vulnerability_id" in filters:
    #     filters["doc_id"] = filters.pop("vulnerability_id")
    if filters.get('masked') is None:
        filters["masked"] = "false"
    if action == "get":
        es_resp = ESConn.search_by_and_clause(CVE_INDEX, filters, req_json.get("start_index", 0),
                                              req_json.get("sort_order", "desc"), size=req_json.get("size", 10),
                                              _source=source_detailed)
        es_resp = format_es_resp_for_api(es_resp["hits"], "vulnerability_id")
        group_by = req_json.get("group_by", None)
        if group_by and group_by in source_detailed:
            group_by_resp = defaultdict(list)
            for es_doc in es_resp:
                group_by_resp[es_doc.get(group_by, "")].append(es_doc)
            es_resp = dict(group_by_resp)
        return set_response(data=es_resp)
    elif action == "delete":
        es_resp = ESConn.search_by_and_clause(CVE_INDEX, filters, req_json.get("start_index", 0),
                                              req_json.get("sort_order", "desc"), size=req_json.get("size", 10),
                                              _source=["_id"])
        no_of_docs_to_be_masked = mask_vulnerabilities(es_resp["hits"])
        return set_response(data={"message": "deleted {0} vulnerabilities".format(no_of_docs_to_be_masked)})
    else:
        raise InvalidUsage("Unsupported action: {0}".format(action))


class VulnerabilityManagement(Resource):
    """
    Vulnerability Management API
    """

    @jwt_required
    def get(self, vulnerability_id):
        """
        Get vulnerability by given vulnerability_id
        ---
        tags:
          - Vulnerability Management
        operationId: getVulnerability
        security:
            - Bearer: []
        parameters:
          - name: vulnerability_id
            in: path
            type: string
            required: true
            description: Vulnerability ID
        responses:
          200:
            description: Request success
            properties:
              data:
                type: object
                description: Vulnerability
              error:
                type: string
                description: Error message, if any. Otherwise `null`
              success:
                type: boolean
                description: Success status
                enum: [true, false]
          400:
            description: Bad request
          401:
            description: Unauthorized
        """
        try:
            if vulnerability_id:
                es_resp = ESConn.search_by_and_clause(
                    CVE_INDEX, {"doc_id": vulnerability_id, "masked": "false"}, 0, size=1,
                    _source=source_detailed)
                return format_response(data=format_es_resp_for_api(es_resp["hits"], "vulnerability_id"))
            else:
                raise InvalidUsage("vulnerability_id is required")
        except Exception as ex:
            raise InternalError(str(ex))

    @jwt_required
    @user_permission(USER_ROLES.ADMIN_USER)
    def delete(self, vulnerability_id):
        """
        Delete a vulnerability doc by vulnerability_id
        ---
        tags:
          - Vulnerability Management
        operationId: deleteVulnerability
        security:
            - Bearer: []
        parameters:
          - name: vulnerability_id
            in: path
            type: string
            required: true
        responses:
          204:
            description: Vulnerability deleted successfully.
          400:
            description: Bad request
          401:
            description: Unauthorized
        """
        try:
            if not vulnerability_id:
                raise InvalidUsage("vulnerability_id is required")
            es_resp = ESConn.search_by_and_clause(
                CVE_INDEX, {"doc_id": vulnerability_id, "masked": "false"}, 0, size=1, _source=["_id"])
            mask_vulnerabilities(es_resp["hits"])
            return format_response(
                data={"message": "deleted vulnerability with vulnerability_id {0}".format(vulnerability_id)})
        except Exception as ex:
            raise InternalError(str(ex))


vulnerability_api_restful.add_resource(VulnerabilityManagement, "/vulnerability/<vulnerability_id>",
                                       endpoint="api_v1_5_vulnerability_mgmt_id")


@vulnerability_api.route("/vulnerability-scan/start-for-tag", methods=["POST"])
@jwt_required
@non_read_only_user
def cve_bulk_start():
    if not request.is_json:
        raise InvalidUsage("Missing json in request")
    if type(request.json) != dict:
        raise InvalidUsage("Request data invalid")
    tags_list = request.json.get("tags_list", [])
    if type(tags_list) != list:
        raise InvalidUsage("tags_list should be list of tags")
    tags_list = [tag for tag in tags_list if tag]
    if not tags_list:
        raise InvalidUsage("tags_list is required")
    scan_types = request.json.get("scan_type", None)
    if not scan_types:
        scan_types = CVE_SCAN_TYPES
    else:
        if type(scan_types) == list:
            scan_types = list(set(scan_types + ["base"]) & set(CVE_SCAN_TYPES))
        else:
            scan_types = CVE_SCAN_TYPES

    node_types = [NODE_TYPE_HOST, NODE_TYPE_CONTAINER, NODE_TYPE_CONTAINER_IMAGE]
    for node_type in node_types:
        topology_data_df_format = {}
        try:
            redis_pipe = redis.pipeline()
            redis_pipe.hgetall(DF_ID_TO_SCOPE_ID_REDIS_KEY_PREFIX + node_type.upper())
            redis_pipe.get(websocketio_channel_name_format(node_type + "?format=deepfence")[1])
            redis_resp = redis_pipe.execute()
            df_id_to_scope_id_map = redis_resp[0]
            if redis_resp[1]:
                topology_data_df_format = json.loads(redis_resp[1])
            if not topology_data_df_format:
                raise DFError("No agents data available")
        except Exception as e:
            raise InvalidUsage(e)
        # filter by given tag
        node_list = []
        redis_lock_keys = []
        redis_pipe = redis.pipeline()
        for node_id, node_details in topology_data_df_format.items():
            try:
                node_tags = node_details.get("user_defined_tags", [])
                if node_tags and (set(node_tags) & set(tags_list)):
                    node = Node(node_id, df_id_to_scope_id_map=df_id_to_scope_id_map,
                                topology_data_df_format=topology_data_df_format)
                    if node_type == NODE_TYPE_HOST:
                        lock_key = "{0}:{1}".format(NODE_ACTION_CVE_SCAN_START, node.host_name)
                    else:
                        if not node.image_name_tag:
                            continue
                        lock_key = "{0}:{1}".format(NODE_ACTION_CVE_SCAN_START, node.image_name_tag)
                    if lock_key in redis_lock_keys:
                        # If same image, different container, already selected, don't scan again
                        continue
                    redis_lock_keys.append(lock_key)
                    redis_pipe.incr(lock_key)
                    node_list.append(node)
            except:
                pass
        redis_resp = redis_pipe.execute()
        for i, node in enumerate(node_list):
            if redis_resp[i] != 1:
                continue
            try:
                node.cve_scan_start(scan_types)
            except:
                pass
        time.sleep(1)
        redis_pipe = redis.pipeline()
        for lock_key in redis_lock_keys:
            redis.delete(lock_key)
        redis_pipe.execute()
    return set_response("OK")


@vulnerability_api.route("/vulnerability/csv", methods=["GET"])
@jwt_required
def vulnerability_csv_download():
    try:
        tag = request.args.get("tag")
        query_body = {}
        if tag and len(tag) > 0:
            results = NodeTags.query.filter(NodeTags.tags.like("%{}%".format(tag))).all()
            nodes = [result.node_name for result in results]
            query_body = {
                "query": {
                    "bool": {
                        "must": [
                            {
                                "bool": {
                                    "should": [
                                        {
                                            "terms": {
                                                "cve_container_image.keyword": nodes
                                            }
                                        },
                                        {
                                            "terms": {
                                                "cve_container_name.keyword": nodes
                                            },
                                        }
                                    ]

                                }
                            }
                        ]
                    }
                }
            }
        csv_buffer = io.StringIO()
        csv_writer = csv.writer(csv_buffer)
        headers = ['@timestamp', 'cve_attack_vector', 'cve_caused_by_package', 'cve_container_image',
                   'cve_container_image_id', 'cve_cvss_score', 'cve_description', 'cve_fixed_in', 'cve_id', 'cve_link',
                   'cve_severity', 'cve_overall_score', 'cve_type', 'host', 'host_name', 'masked', 'scan_id']
        csv_writer.writerow(headers)
        for total_pages, page_count, page_items, page_data in ESConn.scroll(CVE_INDEX, query_body,
                                                                            page_size=100):
            docs = page_data.get('hits', {}).get('hits', [])
            for doc in docs:
                source = doc['_source'] or {}
                csv_writer.writerow([source.get(header) for header in headers])
        return csv_buffer.getvalue()
        # response = make_response(csv_buffer.getvalue())
        # response.headers['Content-Disposition'] = 'attachment; filename=vulnerabilities.csv'
        # response.headers['Content-type'] = 'application/csv'
        # return response
    except Exception as e:
        print("vulnerability_csv_download handler; Err:{}".format(e))
        raise InternalError()


@vulnerability_api.route("/add-cve-scan-log", methods=["POST"])
@jwt_required
@non_read_only_user
def cve_scan():
    """
    Add a CVE scan document to Elastic search
    Input should be a json object with the below format
    ```
    {
        "node_id":"mysql", //mandatory
        "@timestamp":"2018-05-23T07:42:52.678Z", //mandatory
        "actions": "QUEUED", //mandatory
        "cve_scan_message": "" //optional
    }
    ```
    ---
    tags:
      - Common API
    security:
      - Bearer: []
    parameters:
      - name: input_json
        in: body
        type: string
        required: true
        schema:
          properties:
            node_id:
              type: string
              description: The name of container image or host name
              example: mysql:5.6
              required: true
            "@timestamp":
              type: string
              description: String representation of time in ISO format
              example: 2018-05-23T07:42:52.678Z
              required: true
            action:
              type: string
              description: QUEUED|STARTED|COMPLETED|ERROR|WARN|SCAN_IN_PROGRESS|UPLOADING_IMAGE|UPLOAD_COMPLETE
              example: ERROR
              required: true
            cve_scan_mess:
              type: string
              description: Information regarding the CVE scan
              example: Multiple CVE scan not allowed
              required: false
    responses:
      200:
        description: Returns the document ID of the newly inserted document
      400:
        description: bad request (like missing text data)
    """
    if request.method == "POST":
        if not request.is_json:
            raise InvalidUsage("Missing JSON in request")
        body = request.get_json()
        if 'node_id' not in body:
            raise InvalidUsage("node_id is mandatory")
        if '@timestamp' not in body:
            raise InvalidUsage("@timestamp is mandatory")
        if 'action' not in body:
            raise InvalidUsage("action is mandatory")
        if 'masked' not in body:
            body['masked'] = "false"
        body["scan_id"] = body["node_id"] + "_" + datetime.now().strftime("%Y-%m-%dT%H:%M:%S") + ".000"
        body["time_stamp"] = int(time.time() * 1000.0)
        es_response = ESConn.create_doc(CVE_SCAN_LOGS_INDEX, body)
        return set_response(es_response['_id'])


def get_mimetype(data: bytes) -> str:
    """Get the mimetype from file data."""
    f = magic.Magic(keep_going=True, mime=False)
    return f.from_buffer(data)


@vulnerability_api.route("/vulnerability/container_image_registry", methods=["POST"])
@jwt_required
@non_read_only_user
def add_edit_registry_credentials():
    json_params_str = request.form.get("credentials")
    credentials = json.loads(json_params_str)
    extras = {}
    if credentials.get("registry_type", "") == REGISTRY_TYPE_GCLOUD:
        if request.files.get('service_account_json', None) and \
                credentials.get("non_secret", {}).get("registry_hostname", "") and \
                credentials.get("non_secret", {}).get("project_id", ""):
            try:
                service_account_json_str = str(request.files['service_account_json'].read(), "utf-8")
                service_account_json = json.loads(service_account_json_str)
                # Add these just to ensure uniqueness
                project_id = credentials.get("non_secret", {}).get("project_id", "")
                credentials["secret"] = {
                    "project_id_secret": project_id + ":" + service_account_json["project_id"],
                    "private_key_id": project_id + ":" + service_account_json["private_key_id"]
                }
                extras["service_account_json"] = json.dumps(service_account_json)
            except:
                raise InvalidUsage("unable to read 'service_account_json' json file")

    registry_type = credentials.get("registry_type", "")
    secret = credentials.get("secret", {})
    non_secret = credentials.get("non_secret", {})
    name = credentials.get("name", "")
    registry_credential_id = str(credentials.get("id", ""))

    update_flow = False
    if len(registry_credential_id) > 0:
        # Its an update flow
        update_flow = True
        try:
            registry_credential_id = int(registry_credential_id)
        except ValueError:
            raise InvalidUsage("Failed to update; Invalid id: {}".format(registry_credential_id))
        try:
            rc = RegistryCredential.query.get(registry_credential_id)

            if not rc:
                raise InvalidUsage("Failed to update; Not found; {}".format(registry_credential_id))

            if len(name) > 0:
                rc.name = name
            if len(non_secret) > 0:
                rc.non_secret = non_secret
            if len(secret) > 0:
                rc.secret = secret
            if extras:
                rc.extras = extras
            validated = rc.client.validate()
        except InvalidUsage as e:
            raise e
        except (DFError, DFErrorFromThreatMapper) as e:
            logging.error("{} - {}".format(type(e.error), e.error))
            raise InvalidUsage("Failed to update; {}".format(e.message))
        except Exception as e:
            logging.error(e)
            raise InternalError("Failed to update; something went wrong while fetching registry credentials")
    else:
        try:
            rc = RegistryCredential(name=name, registry_type=registry_type,
                                    non_secret=non_secret, secret=secret, extras=extras)
            validated = rc.client.validate()
        except (DFError, DFErrorFromThreatMapper) as e:
            if e.error:
                logging.error("{} - {}".format(type(e.error), e.error))
                raise InvalidUsage("{}".format(e.error))
            raise InvalidUsage('{}'.format(e.message.replace("_", " ").title()))
        except Exception as e:
            logging.error(e)
            raise InternalError("Something went wrong while validating")

    if not validated:
        raise InvalidUsage("Authentication failed for given credentials")

    try:
        rc.save(update=update_flow)
    except IntegrityError as e:
        if update_flow:
            raise InvalidUsage("Failed to update; the resulting registry credential already exists")
        raise InvalidUsage("similar registry credential exists")
    except Exception as e:
        logging.error(e)
    from tasks.registry_images import update_registry_images
    update_registry_images(rc.id)
    status_code = 200 if update_flow else 201
    return set_response(rc.id, status=status_code)


@vulnerability_api.route("/vulnerability/container_image_registry", methods=["GET"])
@jwt_required
def list_container_image_registry():
    current_user = get_jwt_identity()
    user = User.query.filter_by(id=current_user["id"]).one_or_none()
    if not user:
        raise InvalidUsage("User Invalid.")
    registry_type = request.args.get("registry_type", "")
    try:
        query = RegistryCredential.query
        if len(registry_type) > 0:
            query = query.filter_by(registry_type=registry_type)
        credentials = query.all()
    except Exception as e:
        logging.error(e)
        raise InternalError("Failed to list registry credentials")
    credentials_list = []
    image_cve_status = get_image_cve_status()
    for credential in credentials:
        cred = credential.pretty_print()
        cred.update({"unique_images_count": 0, "total_image_tags_count": 0, "total_scanned": 0, "scan_in_progress": 0})
        image_list_details_str = redis.get("{0}:{1}".format(REGISTRY_IMAGES_CACHE_KEY_PREFIX, cred.get("id", "")))
        if image_list_details_str:
            image_list_details = json.loads(image_list_details_str)
            cred["total_image_tags_count"] = len(image_list_details["image_list"])
            _, cred["total_scanned"], cred["scan_in_progress"], cred["unique_images_count"] = \
                get_scan_status_for_registry_images(image_list_details["image_list"], image_cve_status)
        credentials_list.append(cred)
    if user.role.name != USER_ROLES.ADMIN_USER:
        creds_list = []
        for cred in credentials_list:
            cred["credentials"] = {}
            creds_list.append(cred)
        return set_response(creds_list)
    return set_response(credentials_list)


@vulnerability_api.route("/vulnerability/container_image_registry/<int:registry_id>", methods=["DELETE"])
@jwt_required
@non_read_only_user
def delete_container_image_registry(registry_id):
    try:
        credential = RegistryCredential.query.get(registry_id)
    except Exception as e:
        logging.error(e)
        raise InternalError("Failed to get registry credential {}".format(registry_id))
    if not credential:
        raise InvalidUsage("Invalid registry_id")

    try:
        credential.delete()
    except Exception as e:
        logging.error(e)
        raise InternalError("Failed to delete registry credential")
    redis_cache_key = "{0}:{1}".format(REGISTRY_IMAGES_CACHE_KEY_PREFIX, registry_id)
    redis.delete(redis_cache_key)
    filters_key = "{0}{1}:{2}".format(TOPOLOGY_FILTERS_PREFIX, NODE_TYPE_REGISTRY_IMAGE.upper(), registry_id)
    redis.delete(filters_key)
    return set_response("ok")


@vulnerability_api.route("/update_registry_images_list", methods=["POST"])
@jwt_required
def update_registry_images_list():
    if not request.is_json:
        raise InvalidUsage("Missing json in request")
    if type(request.json) != dict:
        raise InvalidUsage("Request data invalid")
    registry_id = request.json.get("registry_id", None)
    if not registry_id:
        raise InvalidUsage("registry_id is mandatory")
    from tasks.registry_images import update_registry_images
    update_registry_images.delay(registry_id)
    return set_response("ok")


@vulnerability_api.route("/vulnerability/top_vulnerable_nodes", methods=["GET"])
@jwt_required
def get_top_vulnerable_nodes():
    number = request.args.get("number")
    time_unit = request.args.get("time_unit")

    if number:
        try:
            number = int(number)
        except ValueError:
            raise InvalidUsage("Number should be an integer value.")

    if bool(number is not None) ^ bool(time_unit):
        raise InvalidUsage("Require both number and time_unit or ignore both of them.")

    if time_unit and time_unit not in TIME_UNIT_MAPPING.keys():
        raise InvalidUsage("time_unit should be one of these, month/day/hour/minute")
    lucene_query_string = request.args.get("lucene_query")
    if lucene_query_string:
        lucene_query_string = urllib.parse.unquote(lucene_query_string)
    else:
        lucene_query_string = ""
    active_hosts = []
    active_images = []
    nodes_data = redis.mget(
        websocketio_channel_name_format(NODE_TYPE_HOST + "?format=deepfence")[1],
        websocketio_channel_name_format(NODE_TYPE_CONTAINER + "?format=deepfence")[1])
    if nodes_data[0]:
        hosts_topology_data = json.loads(nodes_data[0])
        for node_id, node_details in hosts_topology_data.items():
            if node_details.get("host_name") and not node_details.get("is_ui_vm", False) and not node_details.get(
                    "pseudo", False):
                active_hosts.append(node_details["host_name"])
    if nodes_data[1]:
        containers_topology_data = json.loads(nodes_data[1])
        for node_id, node_details in containers_topology_data.items():
            if node_details.get("image_name_with_tag") and not node_details.get("is_ui_vm", False) and \
                    not node_details.get("pseudo", False) and node_details.get("docker_container_state") == "running":
                if node_details["image_name_with_tag"] not in active_images:
                    active_images.append(node_details["image_name_with_tag"])
    # TODO: es max clause
    active_hosts = active_hosts[:ES_MAX_CLAUSE]
    active_images = active_images[:ES_MAX_CLAUSE]
    aggs = {
        "cve_container_image": {
            "terms": {
                "field": "cve_container_image.keyword",
                "size": 5
            },
            "aggs": {
                "scan_id": {
                    "terms": {
                        "field": "scan_id.keyword",
                        "size": 1,
                        "order": {"recent_scan_aggr": "desc"}
                    },
                    "aggs": {
                        "recent_scan_aggr": {
                            "max": {
                                "field": "@timestamp"
                            }
                        },
                        "cve_severity": {
                            "terms": {
                                "field": "cve_severity.keyword",
                                "size": ES_TERMS_AGGR_SIZE
                            }
                        }
                    }
                }
            }
        }
    }
    host_filters = {"node_type": NODE_TYPE_HOST, "cve_container_image": active_hosts}
    host_query = ESConn.aggregation_helper(CVE_INDEX, host_filters, aggs, number,
                                           TIME_UNIT_MAPPING.get(time_unit), lucene_query_string, get_only_query=True)
    container_filters = {"node_type": NODE_TYPE_CONTAINER_IMAGE, "cve_container_image": active_images}
    container_query = ESConn.aggregation_helper(CVE_INDEX, container_filters, aggs, number,
                                                TIME_UNIT_MAPPING.get(time_unit), lucene_query_string,
                                                get_only_query=True)
    search_queries = [
        {"index": CVE_INDEX}, host_query,
        {"index": CVE_INDEX}, container_query
    ]
    aggs_responses = ESConn.msearch(search_queries).get("responses", [])
    response = {NODE_TYPE_HOST: [], NODE_TYPE_CONTAINER_IMAGE: []}

    if "aggregations" in aggs_responses[0]:
        for host_aggs in aggs_responses[0]["aggregations"]["cve_container_image"]["buckets"]:
            for scan_id_bkt in host_aggs["scan_id"]["buckets"]:
                for severity_bkt in scan_id_bkt["cve_severity"]["buckets"]:
                    host_data = {}
                    host_data["node"] = host_aggs["key"]
                    host_data["type"] = severity_bkt["key"]
                    host_data["value"] = severity_bkt["doc_count"]
                    response[NODE_TYPE_HOST].append(host_data)

    if "aggregations" in aggs_responses[1]:
        for image_aggs in aggs_responses[1]["aggregations"]["cve_container_image"]["buckets"]:
            for scan_id_bkt in image_aggs["scan_id"]["buckets"]:
                for severity_bkt in scan_id_bkt["cve_severity"]["buckets"]:
                    image_data = {}
                    image_data["node"] = image_aggs["key"]
                    image_data["type"] = severity_bkt["key"]
                    image_data["value"] = severity_bkt["doc_count"]
                    response[NODE_TYPE_CONTAINER_IMAGE].append(image_data)
    return set_response(data=response)


def node_cve_attack_path(doc_id):
    cve_doc = {}
    try:
        cve_doc = ESConn.get(index=CVE_INDEX, id=doc_id).get("_source", {})
    except:
        raise InvalidUsage("invalid doc_id")
    if not is_network_attack_vector(cve_doc.get("cve_attack_vector", "")):
        return {}
    node_type = cve_doc.get("node_type")
    scope_id = cve_doc.get("cve_container_image") + ";<" + node_type + ">"
    node = Node.get_node("", scope_id, node_type)
    if not node:
        return {}
    return {
        "cve_attack_vector": "network",
        "attack_path": node.get_attack_path_for_node(),
        "ports": node.get_live_open_ports(),
        "cve_id": [cve_doc["cve_id"]]
    }


@vulnerability_api.route("/vulnerabilities/attack_path", methods=["GET"])
@jwt_required
def node_attack_path():
    doc_id = request.args.get("doc_id")
    if doc_id:
        return set_response(data=node_cve_attack_path(doc_id))
    number = request.args.get("number")
    time_unit = request.args.get("time_unit")

    if number:
        try:
            number = int(number)
        except ValueError:
            raise InvalidUsage("Number should be an integer value.")

    if bool(number is not None) ^ bool(time_unit):
        raise InvalidUsage("Require both number and time_unit or ignore both of them.")

    if time_unit and time_unit not in TIME_UNIT_MAPPING.keys():
        raise InvalidUsage("time_unit should be one of these, month/day/hour/minute")
    lucene_query_string = request.args.get("lucene_query")
    if lucene_query_string:
        lucene_query_string = urllib.parse.unquote(lucene_query_string)
    else:
        lucene_query_string = ""

    top_vulnerablities = get_top_vulnerable_nodes_helper(
        number, time_unit, lucene_query_string, size=ES_TERMS_AGGR_SIZE)
    if not top_vulnerablities:
        return set_response(data=[])
    # get top unique nodes
    top_nodes = {}
    top_node_cves = defaultdict(list)
    top_attack_paths = {}
    ignore_nodes = {}
    for vulnerability in top_vulnerablities:
        cve_doc = vulnerability.get("_source", {})
        cve_container_image = cve_doc.get("cve_container_image")
        node_type = cve_doc.get("node_type")
        scope_id = cve_container_image + ";<" + node_type + ">"
        if cve_doc.get("cve_id") not in top_node_cves[scope_id]:
            top_node_cves[scope_id].append(cve_doc.get("cve_id"))
        if len(top_nodes) >= 5:
            continue
        if ignore_nodes.get(scope_id):
            continue
        if cve_container_image in top_nodes:
            continue
        if not is_network_attack_vector(cve_doc.get("cve_attack_vector", "")):
            continue
        node = Node.get_node("", scope_id, node_type)
        attack_path = node.get_attack_path_for_node(top_n=2)
        if not attack_path:
            ignore_nodes[node.scope_id] = True
            continue
        top_attack_paths[node.node_id] = attack_path
        top_nodes[node.node_id] = True
    response = []
    for node_id in top_nodes.keys():
        node = Node(node_id)
        response.append(
            {
                "cve_attack_vector": "network",
                "attack_path": top_attack_paths.get(node_id, []),
                "ports": node.get_live_open_ports(),
                "cve_id": top_node_cves.get(node.scope_id, [])[:3]
            }
        )
    return set_response(data=response)


@vulnerability_api.route("/vulnerability/top_exploits_bubble_chart", methods=["GET"])
@jwt_required
def top_exploits_bubble_chart():
    number = request.args.get("number")
    time_unit = request.args.get("time_unit")

    if number:
        try:
            number = int(number)
        except ValueError:
            raise InvalidUsage("Number should be an integer value.")

    if bool(number is not None) ^ bool(time_unit):
        raise InvalidUsage("Require both number and time_unit or ignore both of them.")

    if time_unit and time_unit not in TIME_UNIT_MAPPING.keys():
        raise InvalidUsage("time_unit should be one of these, month/day/hour/minute")
    lucene_query_string = request.args.get("lucene_query")
    if lucene_query_string:
        lucene_query_string = urllib.parse.unquote(lucene_query_string)
    else:
        lucene_query_string = ""

    return set_response(data=get_top_vulnerable_nodes_helper(number, time_unit, lucene_query_string))


@vulnerability_api.route("/vulnerability/top_exploits", methods=["GET"])
@jwt_required
def get_top_exploits():
    number = request.args.get("number")
    time_unit = request.args.get("time_unit")

    if number:
        try:
            number = int(number)
        except ValueError:
            raise InvalidUsage("Number should be an integer value.")

    if bool(number is not None) ^ bool(time_unit):
        raise InvalidUsage("Require both number and time_unit or ignore both of them.")

    if time_unit and time_unit not in TIME_UNIT_MAPPING.keys():
        raise InvalidUsage("time_unit should be one of these, month/day/hour/minute")
    lucene_query_string = request.args.get("lucene_query")
    if lucene_query_string:
        lucene_query_string = urllib.parse.unquote(lucene_query_string)
    else:
        lucene_query_string = ""

    response = get_top_vulnerable_nodes_helper(number, time_unit, lucene_query_string)
    chart_data = {
        "name": "vulnerabilities",
        "children": [
            {"name": "low", "children": []},
            {"name": "medium", "children": []},
            {"name": "high", "children": []},
            {"name": "critical", "children": []}
        ]}
    vulnerability_severity_map = {
        "low": {},
        "medium": {},
        "high": {},
        "critical": {}
    }
    for info in response:
        severity = info.get("_source", {}).get("cve_severity", "")
        if severity in ["low", "medium", "high", "critical"]:
            node_name = info.get("_source", {}).get("cve_container_image", "")
            if node_name != "":
                sev_count = vulnerability_severity_map[severity].get(node_name, 0)
                vulnerability_severity_map[severity][node_name] = sev_count + 1

    for severity_data in chart_data["children"]:
        severity = severity_data["name"]
        for node_name in vulnerability_severity_map[severity]:
            severity_data["children"].append({"name": node_name,
                                              "value": vulnerability_severity_map[severity][node_name]})

    return set_response(data={"data": response, "chart_data": chart_data})


def get_top_vulnerable_nodes_helper(number, time_unit, lucene_query_string, size=1000, filter_host_name=None):
    topology_data = redis.mget([
        websocketio_channel_name_format(NODE_TYPE_HOST + "?format=deepfence")[1],
        websocketio_channel_name_format(NODE_TYPE_CONTAINER_IMAGE + "?format=deepfence")[1],
        websocketio_channel_name_format(NODE_TYPE_CONTAINER + "?format=deepfence")[1]
    ])
    topology_data = [
        json.loads(topology_data[0]) if topology_data[0] else {},
        json.loads(topology_data[1]) if topology_data[1] else {},
        json.loads(topology_data[2]) if topology_data[2] else {}
    ]
    active_nodes = {}
    for node_id, host_details in topology_data[0].items():
        if filter_host_name:
            if not host_details.get("host_name") == filter_host_name:
                continue
        if host_details.get("host_name") and not host_details.get("pseudo", False) and \
                not host_details.get("is_ui_vm", False):
            active_nodes[host_details["host_name"]] = host_details.get("uptime", 0)
    if not active_nodes:
        return []
    image_creation_time = {}
    datetime_now = datetime.now()
    datetime_str = datetime_now.strftime("%Y-%m-%dT%H:%M:%SZ")
    for node_id, image_details in topology_data[1].items():
        if not image_details.get("name") or image_details.get("pseudo", False):
            continue
        if filter_host_name:
            image_found_in_host = False
            for parent in image_details.get("parents", []):
                if parent["type"] == NODE_TYPE_HOST and parent["label"] == filter_host_name:
                    image_found_in_host = True
            if not image_found_in_host:
                continue
        datetime_created = datetime.strptime(
            image_details.get("docker_image_created_at", datetime_str), "%Y-%m-%dT%H:%M:%SZ")
        duration = datetime_now - datetime_created
        image_creation_time[image_details["name"]] = int(duration.total_seconds())
    for node_id, container_details in topology_data[2].items():
        if container_details.get("docker_container_state") != "running":
            continue
        if filter_host_name:
            if container_details.get("host_name") != filter_host_name:
                continue
        image_name_with_tag = container_details.get("image_name_with_tag")
        if not image_name_with_tag:
            continue
        # Use image build time for containers if available, otherwise use container uptime
        active_nodes[image_name_with_tag] = image_creation_time.get(
            image_name_with_tag, container_details.get("docker_container_uptime", 0))
    recent_scan_ids = get_recent_scan_ids(number, time_unit, None,
                                          {"action": "COMPLETED", "node_id": list(active_nodes.keys())})
    if not recent_scan_ids:
        return []
    top_vulnerabilities = []
    recent_scan_id_chunks = split_list_into_chunks(recent_scan_ids, ES_MAX_CLAUSE)
    sort_expression = "cve_overall_score:desc"
    # Select top MAX_TOP_EXPLOITABLE_VULNERABILITIES number of vulnerabilities with highest score
    for scan_id_chunk in recent_scan_id_chunks:
        filters = {"masked": False, "scan_id": scan_id_chunk}
        resp = ESConn.search_by_and_clause(CVE_INDEX, filters, 0,
                                           number=number, time_unit=TIME_UNIT_MAPPING.get(time_unit),
                                           lucene_query_string=lucene_query_string,
                                           size=ES_TERMS_AGGR_SIZE, custom_sort_expression=sort_expression)
        top_vulnerabilities.extend(resp.get("hits", []))
    host_graph = get_topology_network_graph(topology_data[0])
    image_graph = get_topology_network_graph(topology_data[1])
    node_utils = NodeUtils()
    incoming_internet_host_id = node_utils.get_df_id_from_scope_id("in-theinternet", NODE_TYPE_HOST)
    outgoing_internet_host_id = node_utils.get_df_id_from_scope_id("out-theinternet", NODE_TYPE_HOST)
    incoming_internet_image_id = node_utils.get_df_id_from_scope_id("in-theinternet", NODE_TYPE_CONTAINER_IMAGE)
    outgoing_internet_image_id = node_utils.get_df_id_from_scope_id("out-theinternet", NODE_TYPE_CONTAINER_IMAGE)
    node_with_incoming_connections = {}
    for vulnerability in top_vulnerabilities:
        cve_doc = vulnerability.get("_source", {})
        node_name = cve_doc.get('cve_container_image', '')
        if node_with_incoming_connections.get(node_name):
            continue
        node_type = cve_doc.get("node_type")
        if node_type == NODE_TYPE_HOST:
            node_graph = host_graph
            scope_id = node_name + ";<" + NODE_TYPE_HOST + ">"
            internet_node_id = [incoming_internet_host_id, outgoing_internet_host_id]
        else:
            node_graph = image_graph
            scope_id = node_name + ";<" + NODE_TYPE_CONTAINER_IMAGE + ">"
            internet_node_id = [incoming_internet_image_id, outgoing_internet_image_id]
        try:
            node_id = node_utils.get_df_id_from_scope_id(scope_id, node_type)
            if nx.has_path(node_graph, internet_node_id[0], node_id):
                node_with_incoming_connections[node_name] = True
            elif nx.has_path(node_graph, internet_node_id[1], node_id):
                node_with_incoming_connections[node_name] = True
            else:
                node_with_incoming_connections[node_name] = False
        except:
            node_with_incoming_connections[node_name] = False
    # Sort based on the combine score of cve_score and scaled image build time/uptime and send top 10 vulnerabilities
    # Formula = cve_score * (1+weight), Weight = min(imageBuildTime or uptime/year, 1)
    max_uptime = 365 * 24 * 60 * 60
    uniq_map = {}
    attack_vector_map = {
        0: "local", 1: "network, no live connection", 2: "network, live connection"
    }
    for vulnerability in top_vulnerabilities:
        cve_doc = vulnerability.get("_source", {})
        cve_id = cve_doc.get("cve_id")
        node_name = cve_doc.get('cve_container_image', '')
        network_attack_vector = is_network_attack_vector(cve_doc.get("cve_attack_vector", ""))
        if not network_attack_vector and cve_doc.get('cve_severity') == "low":
            continue
        exploitability_score = 0
        if network_attack_vector:
            if node_with_incoming_connections.get(node_name):
                exploitability_score = 2
            else:
                exploitability_score = 1
        # append this image if this cve present in more than one images
        # introducing a new field
        if cve_id in uniq_map:
            prev_vulnerability = uniq_map.get(cve_id)
            if prev_vulnerability['_source']['cve_overall_score'] > vulnerability['_source']['cve_overall_score']:
                vulnerability = prev_vulnerability
            vulnerable_images = prev_vulnerability.get('_source', {}).get('vulnerable_images', [])
            if node_name not in vulnerable_images:
                vulnerable_images.append(node_name)
            vulnerability['_source']['vulnerable_images'] = vulnerable_images
            new_exp_score = max(exploitability_score, prev_vulnerability.get('_source', {}).get('exploitability_score', []))
            vulnerability['_source']['exploitability_score'] = new_exp_score
            vulnerability['_source']['attack_vector'] = attack_vector_map[new_exp_score]
        else:
            vulnerability['_source']['vulnerable_images'] = [node_name]
            vulnerability['_source']['exploitability_score'] = exploitability_score
            vulnerability['_source']['attack_vector'] = attack_vector_map[exploitability_score]
        vulnerability['_source']['uscore'] = ((1 + (
                min(max_uptime, active_nodes.get(cve_doc.get("cve_container_image"), 0)) /
                (float)(max_uptime))) * cve_doc.get("cve_overall_score"))
        uniq_map[cve_doc.get("cve_id")] = vulnerability
    # Select top 10 uniq vulnerabilities
    uniq_top_vulnerabilities = list(uniq_map.values())
    uniq_top_vulnerabilities.sort(
        key=lambda x: (x.get('_source', {}).get('exploitability_score'), x.get('_source', {}).get('cve_overall_score')),
        reverse=True)
    rank = 0
    current_uscore = None
    for vulnerability in uniq_top_vulnerabilities:
        if current_uscore != vulnerability.get('_source').get('uscore'):
            current_uscore = vulnerability.get('_source').get('uscore')
            vulnerability['_source']['rank'] = rank = rank + 1
        else:
            vulnerability['_source']['rank'] = rank
    return uniq_top_vulnerabilities[:size]


def is_uniq_top_exploit(exploit, uniq_top_exploits):
    for uniq_exploit in uniq_top_exploits:
        if uniq_exploit["_source"]["cve_id"] == exploit["_source"]["cve_id"]:
            return False
    return True
